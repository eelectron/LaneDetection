{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    #check if image is grayscale or color\n",
    "    shape = img.shape\n",
    "    if(len(shape) > 2):               #its a color image\n",
    "        mask_color = (255,)*shape[-1]   #shape[-1] = no. at last index\n",
    "    else:                              #otherwise its a gray image\n",
    "        mask_color = 255\n",
    "      \n",
    "    # Fill the polygon with white\n",
    "    cv2.fillPoly(mask, vertices, mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_filter(image, min_val_y, max_val_y,  min_val_w, max_val_w):\n",
    "    \"\"\"\n",
    "    A function returning a mask for pixels within min_val - max_val range\n",
    "    Inputs:\n",
    "    - image - a BGR image you want to apply function on\n",
    "    - min_val_y - array of shape (3,) giving minumum HSV values for yellow color\n",
    "    - max_val_y - array of shape (3,) giving maximum HSV values for yellow color\n",
    "    - min_val_w - array of shape (3,) giving minumum HSV values for white color\n",
    "    - max_val_w - array of shape (3,) giving maximum HSV values for white color\n",
    "    Returns:\n",
    "    - img_filtered - image of pixels being in given threshold\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask_yellow = cv2.inRange(hsv, min_val_y, max_val_y)\n",
    "    mask_white = cv2.inRange(hsv, min_val_w, max_val_w)\n",
    "    mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "    img_filtered = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 255, 255], thickness=3):\n",
    "    # If there are no lines to draw, exit.\n",
    "    if lines is None:\n",
    "        return\n",
    "    \n",
    "    # Create a blank image that matches the original in size.\n",
    "    line_img = np.zeros_like(img)\n",
    "    \n",
    "    # Loop over all lines and draw them on the blank image.\n",
    "    for line in lines:\n",
    "        line = np.array(line)\n",
    "        line = line.astype(int)\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # Merge the image with the lines onto the original.\n",
    "    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)\n",
    "    \n",
    "    # Return the modified image.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(RGBimage, correct_param = 0.35,equalizeHist = False):\n",
    "    red = RGBimage[:,:,2]\n",
    "    green = RGBimage[:,:,1]\n",
    "    blue = RGBimage[:,:,0]\n",
    "    \n",
    "    red = red/255.0\n",
    "    red = cv2.pow(red, correct_param)\n",
    "    red = np.uint8(red*255)\n",
    "    if equalizeHist:\n",
    "        red = cv2.equalizeHist(red)\n",
    "    \n",
    "    green = green/255.0\n",
    "    green = cv2.pow(green, correct_param)\n",
    "    green = np.uint8(green*255)\n",
    "    if equalizeHist:\n",
    "        green = cv2.equalizeHist(green)\n",
    "        \n",
    "    \n",
    "    blue = blue/255.0\n",
    "    blue = cv2.pow(blue, correct_param)\n",
    "    blue = np.uint8(blue*255)\n",
    "    if equalizeHist:\n",
    "        blue = cv2.equalizeHist(blue)\n",
    "    \n",
    "\n",
    "    output = cv2.merge((blue,green,red))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "            if math.fabs(slope) < 0.2: # <-- Only consider extreme slope\n",
    "                continue\n",
    "            if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "            else: # <-- Otherwise, right group.\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "\n",
    "    min_y = img.shape[0] * (3 / 5) # <-- Just below the horizon\n",
    "    max_y = img.shape[0] # <-- The bottom of the image\n",
    "\n",
    "    poly_left = np.poly1d(np.polyfit(\n",
    "        left_line_y,\n",
    "        left_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "\n",
    "    left_x_start = int(poly_left(max_y))\n",
    "    left_x_end = int(poly_left(min_y))\n",
    "\n",
    "    poly_right = np.poly1d(np.polyfit(\n",
    "        right_line_y,\n",
    "        right_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "\n",
    "    right_x_start = int(poly_right(max_y))\n",
    "    right_x_end = int(poly_right(min_y))\n",
    "    \n",
    "    lines = [[\n",
    "            [left_x_start, max_y, left_x_end, min_y],\n",
    "            [right_x_start, max_y, right_x_end, min_y],\n",
    "            ]]\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_color(img):\n",
    "    '''\n",
    "    img: HSV image\n",
    "    return :image where white and yellow are highlighted and others are black\n",
    "    refrence: Mehdi\n",
    "    '''\n",
    "    yellow_min = np.array([65, 80, 80], np.uint8)\n",
    "    yellow_max = np.array([105, 255, 255], np.uint8)\n",
    "    yellow_mask = cv2.inRange(img, yellow_min, yellow_max)\n",
    "\n",
    "    white_min = np.array([0, 0, 200], np.uint8)\n",
    "    white_max = np.array([255, 80, 255], np.uint8)\n",
    "    white_mask = cv2.inRange(img, white_min, white_max)\n",
    "    \n",
    "    yelWhtMerge = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    img = cv2.bitwise_and(img, img, yelWhtMerge)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryImage(grayImg, thresh):\n",
    "    '''\n",
    "    It takes a gray image and convert it to binary image .\n",
    "    Any value between lower and upper thresh converted to 1.\n",
    "    grayImg: Gray image\n",
    "    thresh: array holds lower and upper color value .Ex [20, 255]\n",
    "    return: binary image\n",
    "    '''\n",
    "    binImg = np.zeros_like(grayImg)\n",
    "    binImg[(grayImg >= thresh[0]) & (grayImg <= thresh[1])] = 1\n",
    "    return binImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorThreshold(img):\n",
    "    '''\n",
    "    img: RGB\n",
    "    return: image , where white and yellow are highlighted and rest are black\n",
    "    '''\n",
    "    #binary threshold values\n",
    "    grayThresh = [20, 255]\n",
    "    \n",
    "    #extract white from RGB img\n",
    "    lower = np.array([98, 104, 94], dtype = \"uint8\")\n",
    "    upper = np.array([255, 255, 255], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(img, lower, upper)\n",
    "    imgWhite = cv2.bitwise_and(img, img, mask = mask).astype(np.uint8)\n",
    "    grayWh = cv2.cvtColor(imgWhite, cv2.COLOR_RGB2GRAY)\n",
    "    binImgWh = binaryImage(grayWh, grayThresh)\n",
    "    \n",
    "    cv2.imshow('grayWh', grayWh)\n",
    "    \n",
    "    #convert img to hls \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    \n",
    "    #extract yellow from HLS\n",
    "    lower = np.array([20, 120, 60], dtype = \"uint8\")\n",
    "    upper = np.array([45, 200, 255], dtype = \"uint8\")\n",
    "    mask = cv2.inRange(hls, lower, upper)\n",
    "    hlsYl = cv2.bitwise_and(img, img, mask = mask).astype(np.uint8)\n",
    "    rgbYl = cv2.cvtColor(hlsYl, cv2.COLOR_HLS2RGB)\n",
    "    grayYl = cv2.cvtColor(rgbYl, cv2.COLOR_RGB2GRAY)\n",
    "    binImgYl = binaryImage(grayYl, grayThresh)\n",
    "    \n",
    "    cv2.imshow(\"grayYl\", grayYl)\n",
    "    \n",
    "    #merge white and yellow \n",
    "    whiteYellow = np.zeros_like(grayYl)\n",
    "    whiteYellow[(binImgWh == 1) | (binImgYl == 1)] = 1\n",
    "    \n",
    "    whiteYellow = cv2.bitwise_or(grayWh, grayYl)\n",
    "    \n",
    "    cv2.imshow('merged', whiteYellow)\n",
    "    #return binary image with white and yellow highlighted\n",
    "    return whiteYellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of after color thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"dataset/ct2.png\", width=600, height=400>\n",
       "<img src=\"dataset/ct3.png\", width=600, height=400>\n",
       "<img src=\"dataset/ct8.png\", width=600, height=400>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"dataset/ct2.png\", width=600, height=400>\n",
    "<img src=\"dataset/ct3.png\", width=600, height=400>\n",
    "<img src=\"dataset/ct8.png\", width=600, height=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(bgrImg):\n",
    "    \"\"\"\n",
    "    An image processing pipeline which will output\n",
    "    an image with the lane lines annotated.\n",
    "    \"\"\"\n",
    "    originalBgrImg = bgrImg\n",
    "    height, width , ch = bgrImg.shape\n",
    "\n",
    "   #corners\n",
    "    region_of_interest_points = [\n",
    "    (0, height),\n",
    "    (0, height*0.65),\n",
    "    (width, height*0.65),\n",
    "    (width, height),\n",
    "    ]\n",
    "    \n",
    "    #defining color thresholds\n",
    "    min_val_y = np.array([20, 100, 100])\n",
    "    max_val_y = np.array([30, 255, 255])\n",
    "    min_val_w = np.array([0, 0, 0])\n",
    "    max_val_w = np.array([0, 0, 255])\n",
    "    \n",
    "    #gray\n",
    "    #gray = cv2.cvtColor(originalBgrImg, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imshow('gray', gray)\n",
    "    \n",
    "    #blur the image\n",
    "    #bgrBlur = gaussian_blur(gray, 5)\n",
    "    \n",
    "    #convert BGR to RGB\n",
    "    rgbImg = cv2.cvtColor(bgrImg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #apply color threshold\n",
    "    whiteYellow = colorThreshold(rgbImg)\n",
    "    \n",
    "    \n",
    "    # Call Canny Edge Detection here.\n",
    "    canny = cv2.Canny(whiteYellow, 171, 255)\n",
    "    #sobelx = cv2.Sobel(canny, cv2.CV_64F, 1, 0, ksize=7)\n",
    "    cropped = region_of_interest(canny, np.array([region_of_interest_points], np.int32) )\n",
    "    lines = hough_lines(cropped, 6,np.pi / 60, 160, 20, 25)\n",
    "    img = draw_lines(original, lines , (255, 255, 255),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-16cd7cf19018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dataset/day-lane.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Take each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../dataset/day-lane.mp4')\n",
    "i = 1\n",
    "while(cap.isOpened()):\n",
    "    # Take each frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    #make video display small\n",
    "    resizedFrame = cv2.resize(frame, (int(frame.shape[0]*.6), int(frame.shape[1]*.6)), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imshow('ori', resizedFrame)\n",
    "    \n",
    "    imageWithLine = pipeline(resizedFrame)\n",
    "    cv2.imshow('final', imageWithLine)\n",
    "    \n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == ord('q'):   #stop video\n",
    "        break\n",
    "    elif k == ord('s'):  #save frame\n",
    "        file = './dataset/whiteYellow'+str(i)+'.jpg'\n",
    "        cv2.imwrite(file, frame)\n",
    "        i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
