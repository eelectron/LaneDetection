{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    #check if image is grayscale or color\n",
    "    shape = img.shape\n",
    "    if(len(shape) > 2):               #its a color image\n",
    "        mask_color = (255,)*shape[-1]   #shape[-1] = no. at last index\n",
    "    else:                              #otherwise its a gray image\n",
    "        mask_color = 255\n",
    "      \n",
    "    # Fill the polygon with white\n",
    "    cv2.fillPoly(mask, vertices, mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_filter(image, min_val_y, max_val_y,  min_val_w, max_val_w):\n",
    "    \"\"\"\n",
    "    A function returning a mask for pixels within min_val - max_val range\n",
    "    Inputs:\n",
    "    - image - a BGR image you want to apply function on\n",
    "    - min_val_y - array of shape (3,) giving minumum HSV values for yellow color\n",
    "    - max_val_y - array of shape (3,) giving maximum HSV values for yellow color\n",
    "    - min_val_w - array of shape (3,) giving minumum HSV values for white color\n",
    "    - max_val_w - array of shape (3,) giving maximum HSV values for white color\n",
    "    Returns:\n",
    "    - img_filtered - image of pixels being in given threshold\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask_yellow = cv2.inRange(hsv, min_val_y, max_val_y)\n",
    "    mask_white = cv2.inRange(hsv, min_val_w, max_val_w)\n",
    "    mask = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "    img_filtered = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return img_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color, thickness):\n",
    "    # If there are no lines to draw, exit.\n",
    "    if lines is None:\n",
    "        return\n",
    "    \n",
    "    # Create a blank image that matches the original in size.\n",
    "    line_img = np.zeros_like(img)\n",
    "    \n",
    "    # Loop over all lines and draw them on the blank image.\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # Merge the image with the lines onto the original.\n",
    "    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)\n",
    "    \n",
    "    # Return the modified image.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correction(RGBimage, correct_param = 0.35,equalizeHist = False):\n",
    "    red = RGBimage[:,:,2]\n",
    "    green = RGBimage[:,:,1]\n",
    "    blue = RGBimage[:,:,0]\n",
    "    \n",
    "    red = red/255.0\n",
    "    red = cv2.pow(red, correct_param)\n",
    "    red = np.uint8(red*255)\n",
    "    if equalizeHist:\n",
    "        red = cv2.equalizeHist(red)\n",
    "    \n",
    "    green = green/255.0\n",
    "    green = cv2.pow(green, correct_param)\n",
    "    green = np.uint8(green*255)\n",
    "    if equalizeHist:\n",
    "        green = cv2.equalizeHist(green)\n",
    "        \n",
    "    \n",
    "    blue = blue/255.0\n",
    "    blue = cv2.pow(blue, correct_param)\n",
    "    blue = np.uint8(blue*255)\n",
    "    if equalizeHist:\n",
    "        blue = cv2.equalizeHist(blue)\n",
    "    \n",
    "\n",
    "    output = cv2.merge((blue,green,red))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "            if math.fabs(slope) < 0.2: # <-- Only consider extreme slope\n",
    "                continue\n",
    "            if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "            else: # <-- Otherwise, right group.\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "\n",
    "    min_y = img.shape[0] * (3 / 5) # <-- Just below the horizon\n",
    "    max_y = img.shape[0] # <-- The bottom of the image\n",
    "\n",
    "    poly_left = np.poly1d(np.polyfit(\n",
    "        left_line_y,\n",
    "        left_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "\n",
    "    left_x_start = int(poly_left(max_y))\n",
    "    left_x_end = int(poly_left(min_y))\n",
    "\n",
    "    poly_right = np.poly1d(np.polyfit(\n",
    "        right_line_y,\n",
    "        right_line_x,\n",
    "        deg=1\n",
    "    ))\n",
    "\n",
    "    right_x_start = int(poly_right(max_y))\n",
    "    right_x_end = int(poly_right(min_y))\n",
    "    \n",
    "    lines = [[\n",
    "            [left_x_start, max_y, left_x_end, min_y],\n",
    "            [right_x_start, max_y, right_x_end, min_y],\n",
    "            ]]\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_color(img):\n",
    "    yellow_min = np.array([65, 80, 80], np.uint8)\n",
    "    yellow_max = np.array([105, 255, 255], np.uint8)\n",
    "    yellow_mask = cv2.inRange(img, yellow_min, yellow_max)\n",
    "\n",
    "    white_min = np.array([0, 0, 200], np.uint8)\n",
    "    white_max = np.array([255, 80, 255], np.uint8)\n",
    "    white_mask = cv2.inRange(img, white_min, white_max)\n",
    "    \n",
    "    yel-wht-merge = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    img = cv2.bitwise_and(img, img, yel-wht-merge)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image):\n",
    "    \"\"\"\n",
    "    An image processing pipeline which will output\n",
    "    an image with the lane lines annotated.\n",
    "    \"\"\"\n",
    "    original = image\n",
    "    height, width , ch = image.shape\n",
    "\n",
    "   #corners\n",
    "    region_of_interest_points = [\n",
    "    (0, height),\n",
    "    (0, height*(3/5)),\n",
    "    (width, height*(3/5)),\n",
    "    (width, height),\n",
    "    ]\n",
    "    \n",
    "    #defining color thresholds\n",
    "    min_val_y = np.array([15,80,190])\n",
    "    max_val_y = np.array([30,255,255])\n",
    "    min_val_w = np.array([0,0,180])\n",
    "    max_val_w = np.array([255, 80, 255])\n",
    "\n",
    "    # Convert to grayscale here.\n",
    "    hsv = hsv_filter(cropped, min_val_y, max_val_y,  min_val_w, max_val_w)\n",
    "    cv2.imshow('hsv', hsv)\n",
    "    \n",
    "    # Call Canny Edge Detection here.\n",
    "    canny = cv2.Canny(gray_image, 150, 250)\n",
    "    cropped = region_of_interest(img, np.array([region_of_interest_points], np.int32) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('blur', gblur)\n",
    "    lines = hough_lines(img, 6,np.pi / 60, 160, 20, 25)\n",
    "    img = draw_lines(original, lines ,thickness=5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dedbf05657f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dataset/day-lane.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Take each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimageWithLine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../dataset/day-lane.mp4')\n",
    "while(cap.isOpened()):\n",
    "    # Take each frame\n",
    "    ret, frame = cap.read()\n",
    "    imageWithLine = pipeline(frame)\n",
    "    #display image with line over it\n",
    "    cv2.namedWindow('final', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('final', imageWithLine)\n",
    "    \n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == ord('q'):   #stop video\n",
    "        break\n",
    "    elif k == ord('s'):  #save frame\n",
    "        file = '../dataset/dl'+str(i)+'.png'\n",
    "        cv2.imwrite(file, frame)\n",
    "        i += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
