{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    #check if image is grayscale or color\n",
    "    shape = img.shape\n",
    "    if(len(shape) == 3):               #its a color image\n",
    "        mask_color = (255,)*shape[-1]   #shape[-1] = no. at last index\n",
    "    else:                              #otherwise its a gray image\n",
    "        mask_color = 255\n",
    "      \n",
    "    # Fill the polygon with white\n",
    "    cv2.fillPoly(mask, vertices, mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySobel(img, orient = 'x', kernel=3, th=100, blackWhite=(0, 255)):\n",
    "    #cvt to gray\n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #extract vertical or horizontal line\n",
    "    if orient == 'x':\n",
    "        absSobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0))\n",
    "    else:\n",
    "        absSobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1))\n",
    "        \n",
    "    #rescale to 8 bit\n",
    "    scaled = np.uint8(255*absSobel/np.max(absSobel))\n",
    "    \n",
    "    #create a blank image and apply thresh\n",
    "    op = np.zeros_like(scaled)\n",
    "    op[scaled > th] = blackWhite[1] #white\n",
    "    op[scaled < th] = blackWhite[0] #black\n",
    "    \n",
    "    return op"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HSV value of yellow and white\n",
    " #defining color thresholds\n",
    "    min_val_y = np.array([15,80,190])\n",
    "    max_val_y = np.array([30,255,255])\n",
    "    min_val_w = np.array([0,0,180])\n",
    "    max_val_w = np.array([255, 80, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def filter_color(img):\n",
    "    yellow_min = np.array([50, 80, 80], np.uint8)\n",
    "    yellow_max = np.array([60, 255, 255], np.uint8)\n",
    "    yellow_mask = cv2.inRange(img, yellow_min, yellow_max)\n",
    "\n",
    "    white_min = np.array([200, 0, 200], np.uint8)\n",
    "    white_max = np.array([255, 0, 255], np.uint8)\n",
    "    white_mask = cv2.inRange(img, white_min, white_max)\n",
    "    \n",
    "    yelWhtMerge = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    img = cv2.bitwise_and(img, img, yelWhtMerge)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(frame):\n",
    "    #get height and width of frame\n",
    "    height, width, channel = frame.shape\n",
    "\n",
    "    #keeping the portion of image which contains lane\n",
    "    topLeftPt = (width*0.30, height*0.60)\n",
    "    topRightPt = (width*0.70, height*0.60)\n",
    "\n",
    "    #this portion contain road\n",
    "    region_of_interest_points = [\n",
    "    (0, height*0.90),\n",
    "    #(0, height*0.60),\n",
    "    topLeftPt,\n",
    "    topRightPt,\n",
    "    #(width, height*0.60),\n",
    "    (width, height*0.90),\n",
    "    ]\n",
    "    \n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = cv2.Canny(img, 80, 185)\n",
    "    img = applySobel(img, 'x', 3)\n",
    "    img = region_of_interest(img, np.array([region_of_interest_points], np.int32))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process and save video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ../dataset/laneDayOut.mp4\n",
      "[MoviePy] Writing video ../dataset/laneDayOut.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13290/13291 [14:49<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../dataset/laneDayOut.mp4 \n",
      "\n",
      "CPU times: user 7min 1s, sys: 1min 56s, total: 8min 58s\n",
      "Wall time: 14min 53s\n"
     ]
    }
   ],
   "source": [
    "laneDay = '../dataset/day-lane.mp4'\n",
    "laneDayOut = './dataset/laneDayOut.mp4'\n",
    "laneVideo = VideoFileClip(laneDay)\n",
    "output = laneVideo.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time output.write_videofile(laneDayOut, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls> <source src=\"../dataset/laneDayOut.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"<video width=\"640\" height=\"480\" controls> <source src=\"{0}\"></video>\"\"\".format(laneDayOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../dataset/day-lane.mp4')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#out = cv2.VideoWriter('./dataset/histSobelx.avi', fourcc, 20, (480,640), isColor='True')\n",
    "\n",
    "#get height and width of frame\n",
    "ret, frame = cap.read()\n",
    "height, width, channel = frame.shape\n",
    "\n",
    "#keeping the portion of image which contains lane\n",
    "topLeftPt = (width*0.30, height*0.60)\n",
    "topRightPt = (width*0.70, height*0.60)\n",
    "\n",
    "#this portion contain road\n",
    "region_of_interest_points = [\n",
    "(0, height*0.90),\n",
    "#(0, height*0.60),\n",
    "topLeftPt,\n",
    "topRightPt,\n",
    "#(width, height*0.60),\n",
    "(width, height*0.90),\n",
    "]\n",
    "\n",
    "i = 1  #image count\n",
    "while(cap.isOpened()):\n",
    "    # Take each frame\n",
    "    ret, frame = cap.read()\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = cv2.Canny(img, 80, 185)\n",
    "    img = applySobel(img, 'x', 3)\n",
    "    img = region_of_interest(img, np.array([region_of_interest_points], np.int32))\n",
    "    cv2.imshow('img', img)\n",
    "    #out.write(img)\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('dataset/ld'+str(i)+'.jpg', frame)\n",
    "        i += 1\n",
    "\n",
    "cap.release()\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((15,15,3), dtype = np.uint8)\n",
    "\n",
    "img[:,:,1] = 255   #saturation\n",
    "img[:,:,2] = 255   #value\n",
    "j = 1\n",
    "#changing hue\n",
    "for i in range(0, 256, 100):\n",
    "    img[:,:,0] = i\n",
    "    #cvt to rgb\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('y', color)\n",
    "    j += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
